{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2179fd9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 23:16:17.066021: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-23 23:16:17.066078: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            1\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              pad64\n",
      "IMAGE_SHAPE                    [256 256   1]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [0.5]\n",
      "MINI_MASK_SHAPE                (256, 256)\n",
      "NAME                           real_pad_100prot\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                131\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "896\n",
      "207\n",
      "WARNING:tensorflow:From /home/ragou/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 23:16:23.621046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-23 23:16:23.621317: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ragou/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-12-23 23:16:23.621480: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ragou/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-12-23 23:16:23.621595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ragou/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-12-23 23:16:23.621702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ragou/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-12-23 23:16:23.621819: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ragou/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-12-23 23:16:23.621924: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ragou/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-12-23 23:16:23.622017: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ragou/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-12-23 23:16:23.622107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ragou/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-12-23 23:16:23.622119: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-23 23:16:24.916090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ragou/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2464: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rois': array([[ 0,  0, 91, 84],\n",
      "       [48, 47, 88, 88],\n",
      "       [ 0,  0, 47, 42]], dtype=int32), 'class_ids': array([1, 1, 1], dtype=int32), 'scores': array([0.97609156, 0.87603307, 0.72118086], dtype=float32), 'masks': array([[[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        ...,\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       [[False, False, False],\n",
      "        [ True, False,  True],\n",
      "        [ True, False,  True],\n",
      "        ...,\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       [[False, False, False],\n",
      "        [ True, False,  True],\n",
      "        [ True, False,  True],\n",
      "        ...,\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        ...,\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       [[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        ...,\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       [[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        ...,\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]]])}]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.layers import concatenate, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# LOSS VERY HIGH WITH THIS PATH !\n",
    "\n",
    "mrcnnpath = \"../\"\n",
    "sys.path.append(mrcnnpath)\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import load_image_gt\n",
    "import multiprocessing as mp\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "class PUDataset(Dataset):\n",
    "    # load the dataset definitions\n",
    "    def load_dataset(self, images_dir, filename_prot):\n",
    "        with open(filename_prot) as filin:\n",
    "            prot_name = filin.readlines()\n",
    "        \n",
    "        self.IMG_SIZE = 256\n",
    "        # define one class\n",
    "        self.add_class(\"dataset\", 1, \"PU\")\n",
    "        # define data locations\n",
    "        # find all images\n",
    "        for image_id,prot in enumerate(prot_name):\n",
    "            prot = prot.strip()\n",
    "            img_path = images_dir + prot  + \"/file_proba_contact.mat\"\n",
    "            annot_path = images_dir + prot + \"/Peeling/Peeling.log\"\n",
    "            annot_path = images_dir + prot + \"/\" + prot + \".out\"\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, annot = annot_path)\n",
    "\n",
    "    def log_to_res(self, logfile):\n",
    "        all_coords = []\n",
    "        with open(logfile, encoding='utf-8') as filin:\n",
    "            for line in filin:\n",
    "                if not line.startswith(\"#\"):\n",
    "                    clean_coord = line.strip().split()[5:]\n",
    "                    xy = [[int(clean_coord[x]),int(clean_coord[x+1])] for x in range(0,len(clean_coord)-1,2)]\n",
    "                    all_coords.append(xy)\n",
    "        return all_coords[-1]\n",
    "\n",
    "    def get_sword_domain(self, output_file):\n",
    "        domain = []\n",
    "        regex = re.compile(\"([\\d+\\-\\d+]+)\")\n",
    "        with open(output_file) as filin:\n",
    "            for line in filin:\n",
    "                match = regex.findall(line)\n",
    "                if match:\n",
    "                    for item in match:\n",
    "                        if \"-\" in item:\n",
    "                            domain.append(item.split(\"-\"))\n",
    "        all_domain = []\n",
    "        try:\n",
    "            first_pos = int(domain[0][0])\n",
    "        except:\n",
    "            return []\n",
    "        for PU in domain[:-1]:\n",
    "            if PU[0] != \"\" and PU[1] != \"\":\n",
    "                all_domain.append([int(PU[0]) - first_pos + 1, int(PU[1]) - first_pos + 1])\n",
    "\n",
    "        return all_domain\n",
    "\n",
    "    \n",
    "    def get_PU(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        path = info['annot']\n",
    "        # PU = self.log_to_res(path)\n",
    "        PU = self.get_sword_domain(path)\n",
    "        PU_list = []\n",
    "        labels = []\n",
    "        for couple in PU:\n",
    "            PU_list = []\n",
    "            for res in couple:\n",
    "                # PU_list.append(int(res * self.IMG_SIZE /shape_image )) # With resizing of images\n",
    "                PU_list.append(res) \n",
    "            labels.append(PU_list)\n",
    "        return labels\n",
    "        \n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        path = info['path']\n",
    "        # print(path, flush=True)\n",
    "\n",
    "        # 255\n",
    "        # image = np.loadtxt(path,encoding='utf-8') * 255\n",
    "        # image = cv2.cvtColor(np.array(image).astype(np.uint8), cv2.COLOR_RGB2BGR).astype(np.uint8)\n",
    "\n",
    "        # 0 1\n",
    "        image = np.loadtxt(path,encoding='utf-8')\n",
    "        image = np.expand_dims(image , axis = 2)\n",
    "        pad = np.full((self.IMG_SIZE,self.IMG_SIZE,1), dtype = np.float32, fill_value= -1.)\n",
    "        pad[:image.shape[0],:image.shape[0]] = image\n",
    "        # image = cv2.cvtColor(np.array(image).astype(np.float32), cv2.COLOR_RGB2BGR).astype(np.float32)\n",
    "\n",
    "        return pad\n",
    "    \n",
    "    # load the masks for an image\n",
    "    def load_mask(self, image_id):\n",
    "        # get details of image\n",
    "        info = self.image_info[image_id]\n",
    "        path = info['annot']\n",
    "        image = self.load_image(image_id)\n",
    "        # load BOX\n",
    "        PU_list = self.get_PU(image_id)\n",
    "        # create one array for all masks, each on a different channel\n",
    "        masks = np.zeros([self.IMG_SIZE, self.IMG_SIZE, len(PU_list)], dtype='uint8')\n",
    "        # create masks\n",
    "        class_ids = list()\n",
    "        for i in range(len(PU_list)):\n",
    "            box = PU_list[i]\n",
    "            x, y = box[0], box[1]\n",
    "            masks[x:y, x:y, i] = 1\n",
    "            class_ids.append(1)\n",
    "        return masks, np.asarray(class_ids, dtype='int32')\n",
    "\n",
    "    def get_PU_score(self, rois, image):\n",
    "       score = []\n",
    "       for i in range(len(rois)):\n",
    "           y1, x1, y2, x2 = rois[i]\n",
    "           B1 = (image[:y1+1,x1:x2][:,:,0]).sum() *2\n",
    "           B2 = (image[y1:y2,x2:][:,:,0]).sum() *2\n",
    "           A = image[y1:y2,x1:x2][:,:,0].sum()\n",
    "           score.append((A-(B1+B2)) / (A+(B1+B2)))\n",
    "       return score\n",
    "    \n",
    "    def calculate_iou(self, y_true, y_pred):\n",
    "        results = []\n",
    "\n",
    "\n",
    "        y_true = np.array(sorted(y_true.tolist()))\n",
    "        y_pred = np.array(sorted(y_pred.tolist()))\n",
    "            \n",
    "        y_true = y_true.astype(np.float32)\n",
    "        y_pred = y_pred.astype(np.float32)\n",
    "\n",
    "\n",
    "        for i in range(0,y_true.shape[0]):\n",
    "            results_PU = []\n",
    "\n",
    "            # boxTrue\n",
    "            x_boxTrue_tleft = y_true[i,0]  # numpy index selection\n",
    "            y_boxTrue_tleft = y_true[i,1]\n",
    "            boxTrue_width = y_true[i,2]\n",
    "            boxTrue_height = y_true[i,3]\n",
    "            area_boxTrue = (boxTrue_width * boxTrue_height)\n",
    "\n",
    "            for j in range(y_pred.shape[0]):\n",
    "\n",
    "                # boxPred\n",
    "                x_boxPred_tleft = y_pred[j,0]\n",
    "                y_boxPred_tleft = y_pred[j,1]\n",
    "                boxPred_width = y_pred[j,2]\n",
    "                boxPred_height = y_pred[j,3]\n",
    "                area_boxPred = (boxPred_width * boxPred_height)\n",
    "\n",
    "\n",
    "                # calculate the bottom right coordinates for boxTrue and boxPred\n",
    "\n",
    "                # boxTrue\n",
    "                x_boxTrue_br = x_boxTrue_tleft + boxTrue_width\n",
    "                y_boxTrue_br = y_boxTrue_tleft + boxTrue_height # Version 2 revision\n",
    "\n",
    "                # boxPred\n",
    "                x_boxPred_br = x_boxPred_tleft + boxPred_width\n",
    "                y_boxPred_br = y_boxPred_tleft + boxPred_height # Version 2 revision\n",
    "\n",
    "\n",
    "                # calculate the top left and bottom right coordinates for the intersection box, boxInt\n",
    "\n",
    "                # boxInt - top left coords\n",
    "                x_boxInt_tleft = np.max([x_boxTrue_tleft,x_boxPred_tleft])\n",
    "                y_boxInt_tleft = np.max([y_boxTrue_tleft,y_boxPred_tleft]) # Version 2 revision\n",
    "\n",
    "                # boxInt - bottom right coords\n",
    "                x_boxInt_br = np.min([x_boxTrue_br,x_boxPred_br])\n",
    "                y_boxInt_br = np.min([y_boxTrue_br,y_boxPred_br]) \n",
    "\n",
    "                # Calculate the area of boxInt, i.e. the area of the intersection \n",
    "                # between boxTrue and boxPred.\n",
    "                # The np.max() function forces the intersection area to 0 if the boxes don't overlap.\n",
    "\n",
    "\n",
    "                # Version 2 revision\n",
    "                area_of_intersection = \\\n",
    "                np.max([0,(x_boxInt_br - x_boxInt_tleft)]) * np.max([0,(y_boxInt_br - y_boxInt_tleft)])\n",
    "\n",
    "                iou = area_of_intersection / ((area_boxTrue + area_boxPred) - area_of_intersection)\n",
    "\n",
    "\n",
    "                # This must match the type used in py_func\n",
    "                iou = iou.astype(np.float32)\n",
    "                #print(f\"BOX {i} MASK {j} IOU {iou}\")\n",
    "                # append the result to a list at the end of each loop\n",
    "                results_PU.append(iou)\n",
    "\n",
    "            results.append(max(results_PU))\n",
    "        # return the mean IoU score for the batch\n",
    "        return np.mean(results)\n",
    "\n",
    "    def compute_iou(self, image_id):\n",
    "\n",
    "            \n",
    "        from mrcnn.model import MaskRCNN\n",
    "        from mrcnn.utils import Dataset\n",
    "        from mrcnn.config import Config\n",
    "        from mrcnn.model import load_image_gt\n",
    "        import tensorflow as tf\n",
    "        config = PUConfig()\n",
    "        # tf.keras.backend.reset_uids() \n",
    "        model = MaskRCNN(mode='inference', model_dir='../results/', config = config )\n",
    "        # load weights (mscoco) and exclude the output layers\n",
    "        now = datetime.datetime.now()\n",
    "\n",
    "        model.load_weights(\"../results/sword_resize_heads20211121T1353/mask_rcnn_sword_resize_heads_0080.h5\", by_name=True)\n",
    "        print(image_id)\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(self, config, image_id)\n",
    "        # image = self.load_image(image_id)\n",
    "        r = model.detect([image])\n",
    "        y_pred = r[0][\"rois\"]\n",
    "        PU = self.get_PU(image_id)\n",
    "        y_true = []\n",
    "\n",
    "        for c in PU:\n",
    "            y_true.append([c[0],c[0],c[1],c[1]])\n",
    "        y_true = np.array(y_true)\n",
    "\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        return self.calculate_iou(y_true, y_pred)\n",
    "\n",
    "\n",
    "    \n",
    "    def perf(self, model, directory, epoch):\n",
    "        all_id = self.image_ids\n",
    "        if len(all_id) < 5000:\n",
    "            dataset = \"test\"\n",
    "        else:\n",
    "            dataset = \"train\"\n",
    "\n",
    "        PU_scores_predict =  []\n",
    "        iou = []\n",
    "        PU_scores_true = []\n",
    "        for image_id in all_id:\n",
    "            y_true = []\n",
    "\n",
    "            start = time.time()\n",
    "            print(image_id)\n",
    "            true_shape = self.load_image(image_id).shape[0]\n",
    "            image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "               load_image_gt(self, model.config, image_id)\n",
    "            r = model.detect([image])[0]\n",
    "            y_pred = r[\"rois\"]\n",
    "            \n",
    "            # Predict score\n",
    "            PU_scores_predict += self.get_PU_score(y_pred, image)\n",
    "            lab = self.get_PU(image_id)\n",
    "           \n",
    "\n",
    "            for i_box in range(len(lab)):\n",
    "                x1, y1 = lab[i_box]\n",
    "                x1, y1 = np.array(lab[i_box]) * model.config.to_dict()[\"IMAGE_MAX_DIM\"] // true_shape\n",
    "                y_true.append([x1, x1, y1, y1])\n",
    "\n",
    "            PU_scores_true += self.get_PU_score(y_true, image)\n",
    "            iou.append(self.calculate_iou(np.array(y_true), y_pred))\n",
    "            print(\"TIME : \", time.time() - start)\n",
    "\n",
    "        np.save(f\"../results/{directory}/predict_scores_{dataset}_{epoch}.npy\", np.array(PU_scores_predict))\n",
    "        np.save(f\"../results/{directory}/true_scores_{dataset}_{epoch}.npy\", np.array(PU_scores_true))\n",
    "        np.save(f\"../results/{directory}/iou_{dataset}_{epoch}.npy\", np.array(iou))\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "# define a configuration for the model\n",
    "class PUConfig(Config):\n",
    "    # define the name of the configuration\n",
    "    NAME = \"real_pad_100prot\"\n",
    "    # number of classes (background + PU)\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    # number of training steps per epoch\n",
    "    # STEPS_PER_EPOCH = 131\n",
    "    STEPS_PER_EPOCH = 131\n",
    "    # # MAX_GT_INSTANCES = 50\n",
    "    # # POST_NMS_ROIS_INFERENCE = 500\n",
    "    # # POST_NMS_ROIS_TRAINING = 1000\n",
    "    # RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
    "    # TRAIN_ROIS_PER_IMAGE = 200\n",
    "    \n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    TOP_DOWN_PYRAMID_SIZE = 256\n",
    "\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (256, 256)  # (height, width) of the mini-mask\n",
    "\n",
    "    BACKBONE = \"resnet50\"\n",
    "\n",
    "    IMAGE_RESIZE_MODE = \"pad64\"\n",
    "    IMAGE_MIN_DIM = IMAGE_MAX_DIM = 256\n",
    "\n",
    "    # IMAGE_MIN_SCALE = 0\n",
    "\n",
    "    MEAN_PIXEL = np.array([0.5])\n",
    "    IMAGE_CHANNEL_COUNT = 1\n",
    "\n",
    "    LEARNING_RATE = 0.0001\n",
    "\n",
    "    def to_txt(self, now):\n",
    "        config_dict = self.to_dict().items()\n",
    "        folder = \"{}{:%Y%m%dT%H%M}\".format(self.NAME.lower(),now)\n",
    "        folder_results = \"../results/\"\n",
    "        filename = \"{}{}{:%Y%m%dT%H%M}.cfg\".format(folder_results, self.NAME.lower(),now)\n",
    "        f = open(filename, \"w\")\n",
    "        for x in config_dict:\n",
    "            f.write(f\"{x}\\n\")\n",
    "        f.close()\n",
    "\n",
    "        os.system(\"move {} {}{}\".format(filename, folder_results, folder))\n",
    "        print(\"Config in {} folder\".format(folder))\n",
    "    def form_dict(self, config_dict):\n",
    "        for key in config_dict:\n",
    "            self.key = config_dict[key]\n",
    "\n",
    "def main():\n",
    "\n",
    "    train_txt = \"../data/train_set_100.txt\"\n",
    "    test_txt = \"../data/test_set_100.txt\"\n",
    "    val_txt = \"../data/val_set_100.txt\"\n",
    "    sword_dir = \"../data/data_sword/\"\n",
    "\n",
    "    train_set = PUDataset()\n",
    "    train_set.load_dataset(sword_dir, train_txt)\n",
    "    train_set.prepare()\n",
    "\n",
    "    val_set = PUDataset()\n",
    "    val_set.load_dataset(sword_dir, val_txt)\n",
    "    val_set.prepare()\n",
    "\n",
    "\n",
    "    test_set = PUDataset()\n",
    "    test_set.load_dataset(sword_dir, test_txt)\n",
    "    test_set.prepare()\n",
    "\n",
    "    config = PUConfig()\n",
    "\n",
    "    config.display()\n",
    "    print(len(train_set.image_ids))\n",
    "    print(len(val_set.image_ids))\n",
    "\n",
    "    # # INFERENCE or TRAINING\n",
    "\n",
    "    model = MaskRCNN(mode=\"inference\", model_dir='../results/', config = config )\n",
    "    model.load_weights(\"../results/real_pad_100prot20211223T1834/mask_rcnn_real_pad_100prot_0005.h5\", by_name=True)\n",
    "    # # load weights (mscoco) and exclude the output layers\n",
    "    # model.load_weights('../mask_rcnn_coco.h5', by_name=T:rue, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    # folder = \"domain_resize1024_01_heads20211129T2050\"\n",
    "    # model.load_weights(f'../results/{folder}/mask_rcnn_domain_resize1024_01_heads_0015.h5', by_name=True) \n",
    "\n",
    "    print(model.detect([train_set.load_image(5)]))\n",
    "    # now = datetime.datetime.now()\n",
    "    # model.keras_model.summary()\n",
    "    # # # # train weights (output layers or 'heads')\n",
    "    # model.train(train_set, val_set, learning_rate=config.LEARNING_RATE, epochs=15,  layers='all')\n",
    "\n",
    "    # config.to_txt(now)\n",
    " \n",
    "    # test_set.perf(model,folder, \"15\")\n",
    "    # train_set.perf(model,folder, \"30\")\n",
    "\n",
    "\n",
    "    # print(\"TIME : \", time.time() - start)\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
